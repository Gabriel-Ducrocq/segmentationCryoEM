Is cuda available ? False
TRAINING IMAGES SHAPE torch.Size([10000, 64, 64])
epoch: 0
0.0
images
Latent parameters:
tensor([[[-4.8608e-02, -1.3386e-04,  7.3560e-03,  ..., -3.6931e-02,
          -2.6762e-02,  4.1134e-02],
         [ 1.4284e-02,  1.9568e-02, -2.1950e-02,  ..., -1.7984e-02,
           4.5469e-02, -3.0436e-02],
         [ 1.0219e+00,  9.9582e-01,  9.6296e-01,  ...,  9.7834e-01,
           9.6762e-01,  1.0268e+00],
         [ 9.4659e-01,  9.9749e-01,  9.9305e-01,  ...,  1.0177e+00,
           1.0013e+00,  9.6016e-01]],
        [[-3.8802e-02, -1.0596e-02,  1.7870e-02,  ..., -3.6147e-02,
          -2.1480e-02,  3.4439e-02],
         [ 2.0399e-02,  2.7910e-03, -5.6855e-03,  ..., -3.4136e-02,
           3.8590e-02, -3.0419e-02],
         [ 1.0222e+00,  1.0001e+00,  9.6913e-01,  ...,  9.8708e-01,
           9.6464e-01,  1.0293e+00],
         [ 9.4215e-01,  1.0002e+00,  9.9147e-01,  ...,  1.0107e+00,
           1.0005e+00,  9.6071e-01]],
        [[-4.9108e-02, -1.2350e-02,  1.2974e-02,  ..., -3.6924e-02,
          -2.4990e-02,  4.2755e-02],
         [ 1.7644e-02,  1.3258e-02, -1.3329e-02,  ..., -1.6487e-02,
           4.8319e-02, -3.6300e-02],
         [ 1.0227e+00,  1.0026e+00,  9.6507e-01,  ...,  9.8277e-01,
           9.6125e-01,  1.0322e+00],
         [ 9.4492e-01,  1.0024e+00,  9.9446e-01,  ...,  1.0097e+00,
           1.0050e+00,  9.5535e-01]],
        ...,
        [[-4.6158e-02, -1.2972e-02,  1.5465e-02,  ..., -2.8309e-02,
          -1.9939e-02,  3.2711e-02],
         [ 1.4639e-02,  5.6012e-03, -1.6405e-02,  ..., -1.7175e-02,
           5.1092e-02, -4.8746e-02],
         [ 1.0233e+00,  9.9610e-01,  9.7440e-01,  ...,  9.8114e-01,
           9.6372e-01,  1.0289e+00],
         [ 9.4591e-01,  9.9922e-01,  9.9057e-01,  ...,  1.0060e+00,
           9.9135e-01,  9.5403e-01]],
        [[-4.6949e-02, -1.1953e-02,  2.2386e-02,  ..., -3.9178e-02,
          -2.4490e-02,  4.0044e-02],
         [ 1.0101e-02,  1.2742e-02, -1.2283e-02,  ..., -1.7895e-02,
           4.5845e-02, -2.7098e-02],
         [ 1.0265e+00,  1.0032e+00,  9.7115e-01,  ...,  9.7832e-01,
           9.6838e-01,  1.0338e+00],
         [ 9.4815e-01,  9.9679e-01,  9.8804e-01,  ...,  1.0144e+00,
           1.0033e+00,  9.5448e-01]],
        [[-4.1534e-02, -1.7046e-02,  1.4678e-02,  ..., -3.5657e-02,
          -1.4499e-02,  5.0314e-02],
         [ 1.7318e-02,  1.3183e-02, -1.4887e-02,  ..., -1.8805e-02,
           5.0317e-02, -3.1053e-02],
         [ 1.0258e+00,  9.9125e-01,  9.7730e-01,  ...,  9.7796e-01,
           9.7012e-01,  1.0325e+00],
         [ 9.4555e-01,  9.9888e-01,  9.9184e-01,  ...,  1.0125e+00,
           9.9840e-01,  9.6174e-01]]], grad_fn=<ReshapeAliasBackward0>)
MU AXIS
torch.Size([100, 4, 3])
tensor([[-4.8608e-02, -1.3386e-04,  7.3560e-03],
        [ 1.4284e-02,  1.9568e-02, -2.1950e-02],
        [ 1.0219e+00,  9.9582e-01,  9.6296e-01],
        [ 9.4659e-01,  9.9749e-01,  9.9305e-01]], grad_fn=<SliceBackward0>)
Time latent: 0.08623099327087402
/Users/gabdu45/PycharmProjects/segmentationCryoEM/imageRenderer.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  ctf = torch.sqrt(torch.tensor(1 - w ** 2, device=self.device)) * torch.sin(torch.tensor(gamma, device=self.device))\
/Users/gabdu45/PycharmProjects/segmentationCryoEM/imageRenderer.py:74: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  - w * torch.cos(torch.tensor(gamma, device=self.device))
/Users/gabdu45/PycharmProjects/segmentationCryoEM/main.py:69: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with autograd.detect_anomaly(check_nan=False):
Mask tensor([[1., 0., 0., 0.],
        [1., 0., 0., 0.],
        [1., 0., 0., 0.],
        ...,
        [0., 0., 0., 1.],
        [0., 0., 0., 1.],
        [0., 0., 0., 1.]], grad_fn=<SoftmaxBackward0>)
RMSD: tensor(499.0620, grad_fn=<NegBackward0>)
Dkl: tensor(21.1045, grad_fn=<NegBackward0>)
DKLS: tensor(-7.2303, grad_fn=<NegBackward0>) tensor(-0., grad_fn=<NegBackward0>) tensor(-0., grad_fn=<NegBackward0>)
LOSS tensor(500.8462, grad_fn=<DivBackward0>)
/Users/gabdu45/PycharmProjects/segmentationCryoEM/main.py:102: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:485.)
  print("LOSS GRAD", loss.grad)
LOSS GRAD None
tensor(461.4722)
tensor(0.3927)
tensor(47.7634)
tensor(140.9431)
tensor(203.3563)
tensor(1.8108)
tensor(85.3960)
tensor(9.4033)
tensor(36.9819)
tensor(35.0214)
STEP
Printing metrics
Running time one iteration: 15.843245029449463
epoch: 0
0.01
images
Latent parameters:
tensor([[[-0.0477, -0.0193,  0.0172,  ..., -0.0351, -0.0189,  0.0436],
         [ 0.0140,  0.0053, -0.0132,  ..., -0.0253,  0.0518, -0.0312],
         [ 1.0172,  0.9993,  0.9806,  ...,  0.9876,  0.9666,  1.0345],
         [ 0.9411,  1.0015,  0.9927,  ...,  1.0154,  1.0017,  0.9603]],
        [[-0.0322, -0.0104,  0.0095,  ..., -0.0397, -0.0217,  0.0340],
         [ 0.0129,  0.0115, -0.0086,  ..., -0.0253,  0.0531, -0.0306],
         [ 1.0234,  0.9952,  0.9681,  ...,  0.9763,  0.9684,  1.0376],
         [ 0.9395,  0.9971,  0.9924,  ...,  1.0152,  1.0007,  0.9569]],
        [[-0.0416, -0.0181,  0.0072,  ..., -0.0411, -0.0264,  0.0336],
         [ 0.0174,  0.0068, -0.0113,  ..., -0.0229,  0.0410, -0.0277],
         [ 1.0182,  0.9997,  0.9645,  ...,  0.9777,  0.9682,  1.0318],
         [ 0.9502,  1.0002,  0.9962,  ...,  1.0080,  1.0041,  0.9583]],
        ...,
        [[-0.0387, -0.0118,  0.0172,  ..., -0.0308, -0.0259,  0.0369],
         [ 0.0248,  0.0123, -0.0099,  ..., -0.0218,  0.0424, -0.0358],
         [ 1.0206,  0.9985,  0.9600,  ...,  0.9721,  0.9674,  1.0265],
         [ 0.9427,  0.9999,  0.9964,  ...,  1.0048,  1.0008,  0.9584]],
        [[-0.0385, -0.0123,  0.0127,  ..., -0.0309, -0.0245,  0.0459],
         [ 0.0179,  0.0063, -0.0099,  ..., -0.0197,  0.0449, -0.0322],
         [ 1.0243,  1.0023,  0.9629,  ...,  0.9813,  0.9666,  1.0302],
         [ 0.9495,  0.9921,  0.9962,  ...,  1.0137,  1.0048,  0.9664]],
        [[-0.0499, -0.0151,  0.0192,  ..., -0.0331, -0.0196,  0.0372],
         [ 0.0126,  0.0186, -0.0217,  ..., -0.0210,  0.0393, -0.0288],
         [ 1.0259,  1.0076,  0.9704,  ...,  0.9789,  0.9589,  1.0304],
         [ 0.9448,  0.9975,  0.9943,  ...,  1.0144,  0.9993,  0.9520]]],
       grad_fn=<ReshapeAliasBackward0>)
MU AXIS
torch.Size([100, 4, 3])
tensor([[-0.0477, -0.0193,  0.0172],
        [ 0.0140,  0.0053, -0.0132],
        [ 1.0172,  0.9993,  0.9806],
        [ 0.9411,  1.0015,  0.9927]], grad_fn=<SliceBackward0>)
Time latent: 0.041892290115356445
Mask tensor([[1., 0., 0., 0.],
        [1., 0., 0., 0.],
        [1., 0., 0., 0.],
        ...,
        [0., 0., 0., 1.],
        [0., 0., 0., 1.],
        [0., 0., 0., 1.]], grad_fn=<SoftmaxBackward0>)
RMSD: tensor(499.4943, grad_fn=<NegBackward0>)
Dkl: tensor(20.9413, grad_fn=<NegBackward0>)
DKLS: tensor(-7.2304, grad_fn=<NegBackward0>) tensor(-0., grad_fn=<NegBackward0>) tensor(-8.9407e-08, grad_fn=<NegBackward0>)
LOSS tensor(501.2769, grad_fn=<DivBackward0>)
LOSS GRAD None
tensor(488.8866)
tensor(0.4509)
tensor(110.3270)
tensor(399.9265)
tensor(230.8473)
tensor(2.4485)
tensor(104.3411)
tensor(13.0714)
tensor(50.1917)
tensor(60.1351)
STEP
Printing metrics
Running time one iteration: 10.377362966537476
epoch: 0
0.02
images
Latent parameters:
tensor([[[-0.0436, -0.0185,  0.0079,  ..., -0.0479, -0.0248,  0.0365],
         [ 0.0260,  0.0014, -0.0111,  ..., -0.0287,  0.0441, -0.0263],
         [ 1.0123,  0.9982,  0.9658,  ...,  0.9764,  0.9693,  1.0282],
         [ 0.9478,  0.9888,  0.9961,  ...,  1.0088,  1.0055,  0.9509]],
        [[-0.0375, -0.0186,  0.0174,  ..., -0.0351, -0.0270,  0.0423],
         [ 0.0128, -0.0082, -0.0071,  ..., -0.0229,  0.0501, -0.0376],
         [ 1.0195,  1.0048,  0.9594,  ...,  0.9812,  0.9617,  1.0347],
         [ 0.9389,  0.9984,  0.9948,  ...,  1.0055,  0.9997,  0.9558]],
        [[-0.0370, -0.0171,  0.0204,  ..., -0.0375, -0.0222,  0.0356],
         [ 0.0245,  0.0068, -0.0112,  ..., -0.0155,  0.0451, -0.0261],
         [ 1.0111,  0.9992,  0.9685,  ...,  0.9757,  0.9678,  1.0226],
         [ 0.9447,  1.0001,  1.0001,  ...,  1.0053,  1.0052,  0.9566]],
        ...,
        [[-0.0397, -0.0196,  0.0169,  ..., -0.0380, -0.0206,  0.0423],
         [ 0.0173,  0.0012, -0.0062,  ..., -0.0263,  0.0453, -0.0257],
         [ 1.0131,  1.0023,  0.9628,  ...,  0.9825,  0.9696,  1.0308],
         [ 0.9429,  0.9963,  0.9930,  ...,  1.0186,  0.9980,  0.9602]],
        [[-0.0400, -0.0037,  0.0174,  ..., -0.0211, -0.0173,  0.0496],
         [ 0.0143,  0.0153, -0.0026,  ..., -0.0193,  0.0503, -0.0429],
         [ 1.0186,  0.9973,  0.9555,  ...,  0.9921,  0.9674,  1.0283],
         [ 0.9454,  0.9981,  0.9995,  ...,  1.0124,  1.0012,  0.9585]],
        [[-0.0347, -0.0224,  0.0151,  ..., -0.0394, -0.0190,  0.0464],
         [ 0.0210,  0.0014, -0.0030,  ..., -0.0244,  0.0490, -0.0277],
         [ 1.0163,  0.9964,  0.9605,  ...,  0.9789,  0.9663,  1.0324],
         [ 0.9497,  0.9936,  0.9952,  ...,  1.0052,  1.0041,  0.9520]]],
       grad_fn=<ReshapeAliasBackward0>)
MU AXIS
torch.Size([100, 4, 3])
tensor([[-0.0436, -0.0185,  0.0079],
        [ 0.0260,  0.0014, -0.0111],
        [ 1.0123,  0.9982,  0.9658],
        [ 0.9478,  0.9888,  0.9961]], grad_fn=<SliceBackward0>)
Time latent: 0.04625082015991211
Mask tensor([[1., 0., 0., 0.],
        [1., 0., 0., 0.],
        [1., 0., 0., 0.],
        ...,
        [0., 0., 0., 1.],
        [0., 0., 0., 1.],
        [0., 0., 0., 1.]], grad_fn=<SoftmaxBackward0>)
RMSD: tensor(499.8504, grad_fn=<NegBackward0>)
Dkl: tensor(20.7526, grad_fn=<NegBackward0>)
DKLS: tensor(-7.2304, grad_fn=<NegBackward0>) tensor(-1.4901e-07, grad_fn=<NegBackward0>) tensor(2.9802e-08, grad_fn=<NegBackward0>)
